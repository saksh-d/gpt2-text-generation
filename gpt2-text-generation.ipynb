{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "880e6121",
   "metadata": {},
   "source": [
    "# GPT-2 Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cceef8",
   "metadata": {},
   "source": [
    "## Dataset: Tiny Shakespeare\n",
    "\n",
    "Available at: https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b658d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeec275",
   "metadata": {},
   "source": [
    "### Download dataset and preview it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6210c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded and saved 'input.txt'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt\"\n",
    "filename = \"input.txt\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    print(f\"Downloaded and saved '{filename}'\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading file: {e}\")\n",
    "except IOError as e:\n",
    "    print(f\"Error saving file: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb7844ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters: 1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the file and preview contents\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Number of characters: {len(text)}\")\n",
    "\n",
    "#Print first 1000 characters\n",
    "print(text[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd02301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "#Create vocabulary\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a284b",
   "metadata": {},
   "source": [
    "## Tokenize the input text\n",
    "\n",
    "Build the tokenizer: Convert the raw text to some sequence of integers, and in this case, each character will be tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "351ff07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 6, 1, 61, 53, 56, 50, 42, 2]\n",
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "#Create mapping from characters to integers\n",
    "\n",
    "stoi = { ch:i for i, ch in enumerate(chars)}\n",
    "itos = { i:ch for i, ch in enumerate(chars)}\n",
    "\n",
    "#building the encoder and decoder\n",
    "encode = lambda x: [stoi[c] for c in x]  #take a string, convert to integers\n",
    "decode = lambda y: ''.join([itos[i] for i in y])  #take a list of integers, convert to string\n",
    "\n",
    "print(encode(\"Hello, world!\"))\n",
    "print(decode(encode(\"Hello, world!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9d956",
   "metadata": {},
   "source": [
    "### Encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3343b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.int64) #or torch.long\n",
    "print(data.shape, data.dtype)\n",
    "\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d891c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform train/test split\n",
    "\n",
    "n = int(0.9*len(data)) #90-10 split for train-val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ed6b7",
   "metadata": {},
   "source": [
    "### Context Length/Block size\n",
    "\n",
    "The data is sampled in chunks, and the length of the chunk of text that is input to the model is defined as \"context length\" or \"block size\".\n",
    "\n",
    "The transformer sees everything from one character up to the block size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7088bb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the target is: 47\n",
      "When input is tensor([18, 47]) the target is: 56\n",
      "When input is tensor([18, 47, 56]) the target is: 57\n",
      "When input is tensor([18, 47, 56, 57]) the target is: 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the target is: 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the target is: 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is: 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is: 58\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]  #+1, as the target for each position is the next character\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]  #offset by 1\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]  #t characters including the t'th character\n",
    "    target = y[t]  #t+1'th character\n",
    "    print(f\"When input is {context} the target is: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaadab6b",
   "metadata": {},
   "source": [
    "### Batches\n",
    "For parallel processing of data, batches of chunks are processed at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  torch.Size([4, 8]) tensor([[59, 44, 44, 43, 56,  1, 51, 43],\n",
      "        [61, 47, 57, 46,  1, 46, 43, 56],\n",
      "        [43, 39, 56,  1, 53,  5, 43, 56],\n",
      "        [52,  1, 54, 43, 56, 57, 59, 39]])\n",
      "targets:  torch.Size([4, 8]) tensor([[44, 44, 43, 56,  1, 51, 43, 10],\n",
      "        [47, 57, 46,  1, 46, 43, 56,  1],\n",
      "        [39, 56,  1, 53,  5, 43, 56, 57],\n",
      "        [ 1, 54, 43, 56, 57, 59, 39, 42]])\n",
      "When input is [59], the target is 44\n",
      "When input is [59, 44], the target is 44\n",
      "When input is [59, 44, 44], the target is 43\n",
      "When input is [59, 44, 44, 43], the target is 56\n",
      "When input is [59, 44, 44, 43, 56], the target is 1\n",
      "When input is [59, 44, 44, 43, 56, 1], the target is 51\n",
      "When input is [59, 44, 44, 43, 56, 1, 51], the target is 43\n",
      "When input is [59, 44, 44, 43, 56, 1, 51, 43], the target is 10\n",
      "When input is [61], the target is 47\n",
      "When input is [61, 47], the target is 57\n",
      "When input is [61, 47, 57], the target is 46\n",
      "When input is [61, 47, 57, 46], the target is 1\n",
      "When input is [61, 47, 57, 46, 1], the target is 46\n",
      "When input is [61, 47, 57, 46, 1, 46], the target is 43\n",
      "When input is [61, 47, 57, 46, 1, 46, 43], the target is 56\n",
      "When input is [61, 47, 57, 46, 1, 46, 43, 56], the target is 1\n",
      "When input is [43], the target is 39\n",
      "When input is [43, 39], the target is 56\n",
      "When input is [43, 39, 56], the target is 1\n",
      "When input is [43, 39, 56, 1], the target is 53\n",
      "When input is [43, 39, 56, 1, 53], the target is 5\n",
      "When input is [43, 39, 56, 1, 53, 5], the target is 43\n",
      "When input is [43, 39, 56, 1, 53, 5, 43], the target is 56\n",
      "When input is [43, 39, 56, 1, 53, 5, 43, 56], the target is 57\n",
      "When input is [52], the target is 1\n",
      "When input is [52, 1], the target is 54\n",
      "When input is [52, 1, 54], the target is 43\n",
      "When input is [52, 1, 54, 43], the target is 56\n",
      "When input is [52, 1, 54, 43, 56], the target is 57\n",
      "When input is [52, 1, 54, 43, 56, 57], the target is 59\n",
      "When input is [52, 1, 54, 43, 56, 57, 59], the target is 39\n",
      "When input is [52, 1, 54, 43, 56, 57, 59, 39], the target is 42\n"
     ]
    }
   ],
   "source": [
    "#looking at one batch of size (batch_size, block_size)\n",
    "\n",
    "batch_size = 4 #how many independent sequences will be processed in parallel\n",
    "block_size = 8 #maximum context length for predictions\n",
    "\n",
    "def get_batch(split):\n",
    "\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(0, len(data) - block_size, (batch_size,))  #generate random positions to grab chunk out of  | torch.randint(low, high, (size:tuple))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])  #offset by 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs: ', xb.shape, xb)\n",
    "print('targets: ', yb.shape, yb)\n",
    "\n",
    "for b in range(batch_size):   #batch dimension\n",
    "    for t in range(block_size):   #time dimension\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"When input is {context.tolist()}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc97a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
